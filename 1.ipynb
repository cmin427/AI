{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNE5BabQFhsKxOU0f5FZTVb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cmin427/AI/blob/master/1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D58Pl6Qp-LU1",
        "colab_type": "text"
      },
      "source": [
        "#삼성 '빅스비 AI 통역 기술' 공개...인터넷 연결 안 해도 실시간 사용\n",
        "\n",
        "삼성 인공지능(AI) 기술이 외국어 음성을 실시간 한글로 통역하는 수준으로 진화했다. 외국어 스피치를 듣는 즉각 한글로 통역한다는 이야기다. 삼성전자는 이르면 이 기술을 내년 차기 프리미엄 스마트폰에 탑재할 계획이다.\n",
        "\n",
        "삼성전자는 4일부터 이틀간 서울 서초 사옥에서 열리는 '삼성 AI포럼 2019'에서 삼성전자 종합기술원이 개발한 실시간 통역 시스템을 처음 공개했다. 행사 첫날 세션 마지막엔 황성우 삼성전자 종합기술원 부사장이 실시간 빅스비 통역 서비스를 구글 음성 번역기와 일대일로 비교하는 시간을 마련했다. 황성우 부사장은 설명 대신 구글 서비스와 정면 비교로 빅스비 AI 경쟁력을 강조했다. 시연에서 삼성 빅스비는 황 부사장이 말한 내용을 정확하게 통역했다. 반면 구글 음성 번역기는 오류가 지속 발생했다.\n",
        "\n",
        "삼성 종기원은 2017년 외국어 텍스트를 번역하는 기계 번역 기술을 발표했다. 지난해엔 복수의 화자가 있는 상황에서도 정확한 음성 인식을 해내는 '엔드투엔드' 음성 인식 기술을 시연했다.\n",
        "\n",
        "올해 종기원은 기존 AI 번역과 음성인식을 합치고 **딥러닝** 기술을 더해 '실시간 통역 서비스'를 선보였다. 서버를 거치지 않는다는 게 핵심이다. 서버를 거치지 않으면 데이터나 전력 소모가 줄어든다. **인터넷 연결이 끊긴** 스마트폰 '비행기 모드'에서도 실시간 통역이 가능하다.\n",
        "\n",
        "구글, 바이두도 실시간 음성 통역 서비스를 이미 선보인 바 있다. 몇몇 애플리케이션에서도 실시간 음성 통역을 제공하지만 품질이 낮다는 평가가 많았다. 삼성은 경쟁사 대비 통역 반응 속도를 높였다. 무엇보다 딥러닝 기술을 적용해 통역 정확성을 대폭 높였다는 데 의미가 있다.\n",
        "\n",
        "삼성전자는 이 기술을 이르면 내년 프리미엄 스마트폰 차기작에 탑재할 것으로 추측된다.\n",
        "\n",
        "삼성전자 종합기술원 관계자는 “삼성 AI 플랫폼 빅스비로 작동시키는 온 디바이스 AI(On-Device AI) 통역 기술은 이제 상용화 수준에 이르렀다”면서 “스마트폰 채택 여부는 삼성전자 모바일 사업부가 결정할 사항”이라고 말했다.\n",
        "\n",
        "올해로 3회를 맞는 삼성 AI 포럼은 세계 저명한 AI 석학을 초청해 최신 연구 동향을 공유하고 미래 혁신 전략을 모색하는 기술 교류의 장이다. 올해는 세계적으로 주목 받는 AI 전문가 강연이 마련됐다. 행사에는 인공 지능 분야 전문가와 교수, 학생 등 1700여명 등이 참석했다.\n",
        "\n",
        "김기남 부회장은 “AI 기술은 이미 사회 전반에 광범위한 영향을 미치고 있다면서 ”세계적인 연구자들과 함께 AI의 미래 발전 방향을 제시하고 세상을 이롭게 할 수 있는 전략을 고민하자“고 말했다.\n",
        "\n",
        "[출처](https://m.etnews.com/20191104000215)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pEkFk-jwAKta",
        "colab_type": "text"
      },
      "source": [
        "#음성 AI, 스마트홈·사물인터넷의 핵심 인터페이스로 부상\n",
        "\n",
        "음성 인공지능(AI)이 스마트홈과 사물인터넷(IoT) 핵심 인터페이스로 부상할 것이라는 분석이 나왔다.\n",
        "\n",
        "삼정KPMG는 16일 발간한 ‘음성 AI 시장의 동향과 비즈니스 기회’ 보고서에서 스마트스피커와 스마트TV, 커넥티드 카 등 음성인식 AI 기술 활용 범위가 증가하고 있으며, 국내외 기업들도 음성 AI 시장에 잇달아 진출하며 대규모 투자와 기술 개발을 진행하고 있다며 이같이 진단했다.\n",
        "\n",
        "음성 AI는 스마트기기로 음성 명령을 인식해 각종 음성 기반 서비스를 활용하는 기술이다. 최근 딥러닝 기술 발달과 고객 접점 단말 확대, 음성 인식 기술에 대한 사용자 인식 및 행동 변화로 관련 시장이 급성장하고 있다.\n",
        "\n",
        "보고서는 음성 AI 시장 가치사슬을 기반 기술, 플랫폼, 하드웨어, 서비스로 구분했다. 보고서에 따르면 음성 AI 기반 기술은 음성 인식, 자연어 처리, 시맨틱 분석, 음성 합성 등이 있고 딥러닝과 빅데이터, 클라우드가 기반 기술로 활용된다.\n",
        "\n",
        "구글(어시스턴트), 아마존(알렉사) 등 글로벌 IT 기업은 8년 전부터 음성 에이전트라고도 불리는 음성 AI 플랫폼을 출시하고 음성 AI 플랫폼 시장 선점을 위한 경쟁에 나서고 있다. 국내에서는 통신사와 가전 업체, 인터넷 기업들이 주도적으로 음성 AI 플랫폼을 출시하고 있으며, 한국어에 특화된 음성 인식 및 음성 합성 성능과 함께, 국내 인터넷 및 모바일 서비스와의 연동을 강점으로 내세우고 있다.\n",
        "\n",
        "보고서에 따르면 최근에는 파트너 기업들과 제휴를 통한 영향력 확대와 개방형 생태계 조성이 주된 트렌드로 나타남에 따라 기업 간 합종연횡과 외부의 개발자를 끌어들이려는 플랫폼 기업의 노력도 두드러지는 모습을 보이고 있다.\n",
        "\n",
        "보고서는 음성 AI 시장 확대의 주된 이유로 스마트스피커 보급 증가를 꼽았다. 글로벌 시장조사업체 카날리스(Canalys)에 따르면, 전 세계 스마트스피커 연간 출하량은 지난 2018년 7,800만 대에서 2019년 1억2,460만 대로 1년새 60% 증가한 것으로 조사됐다.\n",
        "\n",
        "스마트TV와 커넥티드 카에서도 음성 AI 기술 활용이 늘어나면서 하드웨어 접점을 늘려가고 있다. 스마트TV 제조사들은 음성 AI 플랫폼을 탑재하며 냉장고, 에어컨, 스마트 스피커 등을 컨트롤하는 스마트홈 허브로 발돋움하기 위해 경쟁하고 있으며, 운전 중 자동차에서 사용하기 편리하고 안전하다는 장점에 힘입어 커넥티드 카 시스템에도 음성 AI 시스템이 활발하게 탑재되고 있다.\n",
        "\n",
        "음성 AI 유망 서비스로는 새로운 커머스 플랫폼으로서의 잠재력을 보유한 보이스 커머스와 자동차에서 메인 인터페이스로 활용 가능한 차량 내 음성 서비스, 여러 외부업체들의 참여로 다양한 서비스 출시가 가능한 확장 기능 등이 제시됐다.\n",
        "\n",
        "보고서는 음성 AI 시장 확대를 위해 보안과 프라이버시 문제 해결, 음성 AI 성능 향상, 다양한 응용 서비스와 킬러 서비스 등장이 필요하다고 제언했다. 데이터 수집과 활용이 필수적으로 요구되는 음성 AI 단말과 플랫폼 특성 상 보안과 프라이버시 문제를 해결해야 시장 확대가 가능하며, 음성 인식률의 향상과 문맥을 이해하는 음성 AI 개발을 통한 성능 향상도 요구된다고 설명했다. 또한, 사용자의 호응을 얻을 수 있는 핵심 서비스가 등장해야 음성 AI의 주류 시장 진입이 가능하다고 덧붙였다.\n",
        "\n",
        "염승훈 삼정KPMG 전자정보통신본부 파트너는 “음성 AI 시장 생태계 구축과 선점을 위한 기술과 플랫폼, 하드웨어 업체간 제휴와 경쟁이 심화되면서 음성 인식 기술 기업에 대한 M&A가 활발히 진행될 것”이라며 “특히 향후 스마트홈·IoT 허브 역할을 장악하기 위한 음성 AI 경쟁이 치열해질 것으로 전망된다”고 말했다.\n",
        "\n",
        "[출처](https://www.sedaily.com/NewsVIew/1Z1HY4JC9E)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8P-RO8UHB4OD",
        "colab_type": "text"
      },
      "source": [
        "#You Only Look Once 조셉 레드몬, 비전 컴퓨팅 연구를 그만두다.\n",
        "\n",
        "조셉 레드몬은 워싱턴 대학교 산하의 PLSE 연구실(실제로는 그룹에 더 가까운 커뮤니티)에서 연구하고 있고 C기반의 DarkNet 프레임워크를 개발한 것으로 유명하다. 아마 YOLO가 속도를 추구하는 만큼 파이썬 기반의 프레임워크가 아닌 C로 작성하여 구현한 듯하다. 그는 2016년에는 YOLO v1을, 2017년에는 YOLO v2를 발표하고 2018에는 개선한 버전인 YOLO v3를 차례로 공개하였다. 이렇게 활발한 연구활동을 하던 그가 2020년 2월 21일, 더 이상 비전 컴퓨팅 연구를 하지 않겠다라고 선언했다.\n",
        "\n",
        "조셉 레드몬이 지금까지 진행한 연구가 공익적 목적보다는 군사적, 개인정보 침해로 활용될 가능성이 커서 잠정적으로 연구를 중단한다고 한다. 인공지능의 발전이 인류에 위협이 될 수 있다는 우려는 꾸준히 제기 되었다. 누군가는 “인공지능의 위협을 막는 방법은 다른 연구자가 발견할 것이기 때문에 우리는 걱정하지 않아도 된다.” 라고 했지만 조셉 레드몬은 그렇게 생각하지 않았다.\n",
        "\n",
        "\n",
        "#YOLO(You Only Look Once) 란? \n",
        "* You Only Look Once: 이미지 전체를 단 한번만 본다.\n",
        "딥러닝 모델을 객체 탐지에 쓰인 모델은 YOLO 이전에 R-CNN 모델 등이 존재했다. 대표적으로 R-CNN과 비교하자면 R-CNN은 이미지에서 일정한 규칙으로 이미지를 여러장 쪼개서 CNN모델을 통과시키기 때문에 한 장의 이미지에서 객체 탐지를 수행해도 실제로는 수 천장의 이미지를 모델에 통과시킨다. 반면, YOLO는 이미지 전체를 말 그대로 단 한번만 본다.\n",
        "* Unified: 통합된 모델을 사용한다.\n",
        "다른 객체 탐지 모델 들은 다양한 전처리 모델과 인공 신경망을 결합해서 사용하지만, YOLO는 단 하나의 인공신경망에서 이를 전부 처리한다. 이런 특징 때문에 YOLO가 다른 모델보다 간단해 보인다.\n",
        "* Real-time Object Detection: 실시간 객체 탐지\n",
        "이 특징이 오늘 날 YOLO를 유명하게 만들었다. YOLO가 높은 성능으로 객체를 탐지하는 모델은 아니지만, 실시간으로 여러장의 이미지를 탐지할 수 있다. “빠르다”는 이름이 붙은 Fast R-CNN이 0.5 FPS(초당 프레임 수)의 성능을 가진 반면에 YOLO는 45 FPS의 성능을 가진다. 이는 영상을 스트리밍 하면서 동시에 화면 상의 물체를 부드럽게 구분할 수 있을 정도다.\n",
        "\n",
        "YOLO의 감지 시스템은 R-CNN과는 달리 합성곱 신경망을 단 한 번 통과시킨다. 신경망의 결과로는 각 객체의 바운딩 박스와 해당 객체가 무엇인지 분류 확률을 출력한다. 최종적으로는 이 값을 Non-max suppression을 통해 리전을 결정한다.\n",
        "\n",
        "[출처](https://medium.com/curg/you-only-look-once-%EB%8B%A4-%EB%8B%A8%EC%A7%80-%ED%95%9C-%EB%B2%88%EB%A7%8C-%EB%B3%B4%EC%95%98%EC%9D%84-%EB%BF%90%EC%9D%B4%EB%9D%BC%EA%B5%AC-bddc8e6238e2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "puj_u5jrB4C6",
        "colab_type": "text"
      },
      "source": [
        "#‘자율주행차’ 7월부터 판매 가능\n",
        "\n",
        "올해 7월부터 운전자가 운전대를 잡지 않아도 운행(자동차로유지 기능)되는 자율주행자동차의 출시·판매가 가능해진다.\n",
        "국토교통부는 ‘자동차 및 자동차부품의 성능과 기준에 관한 규칙’을 개정해 안전기준을 ‘부분 자율주행차(레벨 3)’ 수준으로 끌어올렸다고 5일 밝혔다. 기존의 안전기준(레벨 2)은 차로유지기능을 작동시켜도 운전자가 운전대에서 손을 떼면 경고음이 울리는 ‘지원’ 수준에 머물러 있었는데 이를 개정하면서 운전자의 손길이 없어도 주행이 가능한 단계까지 허용한 것이다. 미국 자동차공학회는 자율주행을 0~5단계로 구분하고 있는데 레벨 1·2는 운전자 지원 기능이 탑재된 차량이고 레벨 3부터 자율주행차로 분류된다. 국토부는 우리나라의 레벨 3 안전기준이 유엔 산하 자동차안전기준국제조화포럼에서 논의되고 있는 국제적인 동향과 국내의 업계·학계 의견수렴을 거쳐 마련됐으며 세계 최초로 도입된 것이라고 덧붙였다.\n",
        "안전기준에서는 차로유지 기능을 자율주행차에 맡기되 운전자의 개입이 필요한 다양한 상황에 적절히 대응할 수 있는 규정도 함께 제시했다. 자율주행차는 고속도로 출구처럼 작동 영역을 벗어나는 상황이 예정되면 15초 전에 ‘운전전환 요구’가 뜨게 되고 10초 안에 운전자의 반응이 없으면 안전을 위해 속도를 줄이고 비상경고 신호를 작동해야 한다. 갑작스러운 도로 공사 등 예상치 못한 상황에서는 운전전환 요구가 즉시 이뤄지며, 충돌이 임박하는 등 운전자가 대응할 수 없을 정도의 긴급 상황에선 자율주행차가 비상운행 기준에 따라 감속과 조향을 통해 충격을 최소화해야 한다. 자율주행 시스템 고장에 대비해 안전보장용 이중화 시스템 설계도 명시했다.\n",
        "국토부 이창기 첨단자동차기술과장은 “이번에 도입된 자율주행차 안전기준을 기반으로 국제 안전기준 논의에도 적극적으로 참여해 한국이 자율주행차 국제기준을 선도하도록 추진할 예정”이라며 “자율주행차 분야에서 제도가 미비하여 산업 발전에 애로가 생기는 일이 없도록 노력하겠다”고 밝혔다.\n",
        "\n",
        "[출처](\n",
        "http://www.hani.co.kr/arti/economy/car/923202.html#csidxd7aa40e15fab0fab2d12c2ab44c5cbe)"
      ]
    }
  ]
}